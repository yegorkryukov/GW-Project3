{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/anaconda3/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For debugging turn on logging to console\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "# mongodb\n",
    "import pymongo as pm\n",
    "\n",
    "# fine-tuned newspaper lib\n",
    "from resources.newspaper import newspaper\n",
    "from resources.newspaper.newspaper.source import Source\n",
    "from resources.newspaper.newspaper.article import Article\n",
    "\n",
    "import bs4 as bs\n",
    "from urllib.parse import urljoin\n",
    "from dateutil.parser import parse as date_parser\n",
    "\n",
    "import requests\n",
    "from pprint import pprint\n",
    "\n",
    "import requests\n",
    "from lxml import html\n",
    "import json\n",
    "from resources.config import *\n",
    "from datetime import timedelta\n",
    "\n",
    "USERNAME = username\n",
    "PASSWORD = password\n",
    "apiKey = apiKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize PyMongo to work with MongoDBs\n",
    "conn = 'mongodb://localhost:27017'\n",
    "client = pm.MongoClient(conn, maxPoolSize=200)\n",
    "\n",
    "# define db \n",
    "# DB_NAME = 'scrape'\n",
    "DB_NAME = 'FINALP'\n",
    "db = client[DB_NAME]\n",
    "\n",
    "def saveToDB(db, collection, url, html, meta={}):\n",
    "    \"\"\"\n",
    "    Saves a document to mongoDB, making sure there are no duplicates by \n",
    "    'url' value\n",
    "    \n",
    "    Parameters:\n",
    "    --------\n",
    "    db, collection  : mongo db connection\n",
    "    url, html, meta : values to store\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    Saved document\n",
    "    \"\"\"\n",
    "    collection = db[collection]\n",
    "    collection.update_one(\n",
    "        {'url' : url},\n",
    "        {\n",
    "            '$set':\n",
    "                {'url' : url,\n",
    "                 'html' : html,\n",
    "                 'meta' : meta\n",
    "                }\n",
    "        }\n",
    "        ,\n",
    "        upsert=True\n",
    "    )\n",
    "    log.debug(f'Saved to DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): myaccount.nytimes.com\n",
      "DEBUG:urllib3.connectionpool:https://myaccount.nytimes.com:443 \"GET /auth/login HTTP/1.1\" 200 1505\n",
      "DEBUG:urllib3.connectionpool:https://myaccount.nytimes.com:443 \"POST /auth/login HTTP/1.1\" 200 1534\n"
     ]
    }
   ],
   "source": [
    "# open browser session and login\n",
    "\n",
    "LOGIN_URL = \"https://myaccount.nytimes.com/auth/login\"\n",
    "session_requests = requests.session()\n",
    "\n",
    "# Get login csrf token\n",
    "result = session_requests.get(LOGIN_URL)\n",
    "tree = html.fromstring(result.text)\n",
    "authenticity_token = json.loads(tree.xpath(\"//div[@id='myAccountAuth']/@data-auth-options\")[0].replace(\"'\", \"\\\"\"))['authToken']\n",
    "\n",
    "# Create payload\n",
    "payload = {\n",
    "    \"username\": USERNAME, \n",
    "    \"password\": PASSWORD, \n",
    "    \"csrfmiddlewaretoken\": authenticity_token\n",
    "}\n",
    "\n",
    "# Perform login\n",
    "result = session_requests.post(LOGIN_URL, data = payload, headers = dict(referer = LOGIN_URL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup newsapi.org credentials\n",
    "collection = 'nytimes'\n",
    "\n",
    "# logging.getLogger('urllib3').setLevel(logging.WARNING)\n",
    "\n",
    "page     = 1\n",
    "source   = 'the-new-york-times'\n",
    "pageSize = 100\n",
    "\n",
    "earliest_date = date_parser('2017-01-01')\n",
    "latest_date = date_parser('2017-11-06')\n",
    "\n",
    "params = {\n",
    "        'apiKey'   : apiKey,\n",
    "        'pageSize' : pageSize,\n",
    "        'page'     : page,\n",
    "        'from'     : earliest_date,\n",
    "        'to'       : latest_date,\n",
    "        'sources'  : source\n",
    "    }\n",
    "\n",
    "# base url\n",
    "api_url = 'https://newsapi.org/v2/everything?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scrape news\n",
    "while latest_date > earliest_date:\n",
    "    log.debug(f'Requesting period: {latest_date - timedelta(30)}-{latest_date}')\n",
    "       \n",
    "    page = 1\n",
    "    params['from'] = latest_date - timedelta(30)\n",
    "    params['to']   = latest_date\n",
    "    \n",
    "    r = requests.get(api_url, params=params)\n",
    "\n",
    "    totalPages = r.json()['totalResults']//100+1\n",
    "\n",
    "    log.debug(f'TOTAL PAGES FOR {source}: {totalPages}')\n",
    "    \n",
    "    for p in range(page,totalPages):\n",
    "        log.debug(f'\\n\\n PROCESSING PAGE: {page}\\n')\n",
    "\n",
    "        params['page'] = page\n",
    "        page += 1\n",
    "\n",
    "        r = requests.get(api_url, params=params)\n",
    "\n",
    "        for a in r.json()['articles']:\n",
    "            try:\n",
    "                url = a['url']\n",
    "                log.debug(f\"Processing url: {url}\")\n",
    "                result = session_requests.get(url, headers = dict(referer = url))\n",
    "                soup = bs.BeautifulSoup(result.text, 'lxml')\n",
    "                text = ''\n",
    "                for d in soup.findAll('div', {'class':'StoryBodyCompanionColumn'}):\n",
    "                    text += d.text\n",
    "\n",
    "                saveToDB(db, collection, url, result.text, meta={\n",
    "                    'date'    : date_parser(a['publishedAt']),\n",
    "                    'title'   : a['title'],\n",
    "                    'text'    : text,\n",
    "                    'authors' : a['author']\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                log.debug(e)\n",
    "\n",
    "    latest_date -= timedelta(30)\n",
    "            \n",
    "log.debug('Ended scrape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2017, 11, 5, 11, 0, 47)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# collection | empty query | sort in pymongo accepts list of tuples \n",
    "# as arguments as opposed to dictionary for native mongoDB queries\n",
    "# because python's dict does not store values order\n",
    "# native mongoDB: .sort({\"meta.date\": 1})  –dict-like object\n",
    "# pymongo way:    .sort([(\"meta.date\",1)]) –list of tuples\n",
    "# the result is pymongo cursor that is iterable as list\n",
    "# thus we access the first item of the list as [0] and then\n",
    "# access the underlying dict object with ['meta']['date']\n",
    "\n",
    "db[collection].find().sort([(\"meta.date\",1)]).limit(1)[0]['meta']['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
